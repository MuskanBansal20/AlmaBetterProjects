{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuskanBansal20/AlmaBetterProjects/blob/main/Netfilx_Movies_and_TV_Shows_Clustering_Project_Muskan_Bansal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -  **Netfilx Movies and TV Shows Clustering**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary**    -  \n",
        "\n"
      ],
      "metadata": {
        "id": "Wyz2g0p-wfIk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix, the world’s largest on-demand internet streaming media and online DVD movie rental service provider.it Founded August 29, 1997, in Los Gatos, California by Marc and Reed. It has 69 million members in over 60 countries enjoying more than 100 million hours of TV shows and movies per day Netflix is the world’s leading internet entertainment service with enjoying TV series, documentaries, and feature films across a wide variety of genres and languages. I was curious to analyze the content released in Netflix platform which led me to create these simple, interactive, and exciting visualizations and find similar groups of people."
      ],
      "metadata": {
        "id": "p1YPvZkhwnJ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Github Link**    -  \n",
        "\n"
      ],
      "metadata": {
        "id": "gBBZ-uEywst-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "x0YBgErJw0Og"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix is the world's largest online streaming service provider, with over 220 million subscribers as of 2022-Q2. It is crucial that they effectively cluster the shows that are hosted on their platform in order to enhance the user experience, thereby preventing subscriber churn.\n",
        "We will be able to understand the shows that are similar to and different from one another by creating clusters, which may be leveraged to offer the consumers personalized show suggestions depending on their preferences.\n",
        "The goal of this project is to classify/group the Netflix shows into certain clusters such that the shows within a cluster are similar to each other and the shows in different clusters are dissimilar to each other."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Define Your Business Objective?** "
      ],
      "metadata": {
        "id": "PH-0ReGfmX4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To offer the consumers personalized show suggestions depending on their preferences"
      ],
      "metadata": {
        "id": "PhDvGCAqmjP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required. \n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits. \n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "\n",
        "5. You have to create at least 20 logical & meaningful charts having important insights.\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule. \n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import math\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "from matplotlib.pyplot import figure\n",
        "import plotly.graph_objects as go\n",
        "import plotly.offline as py\n",
        "import plotly.express as px\n",
        "from datetime import datetime\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mounting the google drive to access the files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/Full Stack Data Science/NETFLIX_MOVIES_AND_TV_SHOWS_CLUSTERING_Dataset.csv')"
      ],
      "metadata": {
        "id": "CEhiayUv1809"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First 10 rows\n",
        "data.head(10)"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns \n",
        "print(\"number of rows : \", data.shape[0])\n",
        " \n",
        "print(\"number of columns : \", data.shape[1])"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "data.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "len(data[data.duplicated()])"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "print(data.isnull().sum().sort_values())"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling Null Values\n",
        "data['cast'].fillna(value='No cast',inplace=True)\n",
        "data['country'].fillna(value=data['country'].mode()[0],inplace=True)\n"
      ],
      "metadata": {
        "id": "7GUHf3BgHGAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#'date_added' and 'rating' contains an insignificant portion of the data so we will drop them from the dataset\n",
        "data.dropna(subset=['date_added','rating'],inplace=True)"
      ],
      "metadata": {
        "id": "5u4rujf6HOpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping Director Column\n",
        "data.drop(['director'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "kjeQtCT_HXDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "print(data.isnull().sum().sort_values())"
      ],
      "metadata": {
        "id": "MbIU7-_pHcEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "# Checking Null Value by plotting Heatmap\n",
        "sns.heatmap(data.isnull(), yticklabels=False, cmap='viridis')"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset consists of tv shows and movies available on Netflix as of 2019. The dataset is collected from flixable which is a third-party Netflix search engine. \n",
        "In 2018, they released an interesting report which shows that the number of TV shows on Netflix has nearly tripled since 2010. The streaming service’s number of movies has decreased by more than 2,000 titles since 2010, while its number of TV shows has nearly tripled. It will be interesting to explore what all other insights can be obtained from the same dataset. Integrating, this dataset with other external datasets \n",
        "such as IMDB ratings, rotten tomatoes can also provide many interesting findings.\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "data.columns"
      ],
      "metadata": {
        "id": "n87BaXA_42-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "data.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. show_id : Unique ID for every Movie / Tv Show\n",
        "2. type : Identifier - A Movie or TV Show\n",
        "3. title : Title of the Movie / Tv Show\n",
        "4. director : Director of the Movie\n",
        "5. cast : Actors involved in the movie / show\n",
        "6. country : Country where the movie / show was produced\n",
        "7. date_added : Date it was added on Netflix\n",
        "8. release_year : Actual Release Year of the movie / show\n",
        "9. rating : TV Rating of the movie / show\n",
        "10. duration : Total Duration - in minutes or number of seasons\n",
        "11. listed_in : Genere\n",
        "12. description: The Summary description"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for var in data.columns.tolist():\n",
        "  print(\"No. of unique values in \",var,\"is\",data[var].nunique(),\".\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA"
      ],
      "metadata": {
        "id": "Hk9b_1Axbt7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['type'].value_counts()"
      ],
      "metadata": {
        "id": "H8F4PfqgbG6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#countplot to visualize the number of movies and tv_shows in type column\n",
        "sns.countplot(data['type'])"
      ],
      "metadata": {
        "id": "tbU12zEzbGyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['rating']"
      ],
      "metadata": {
        "id": "iRrYWWfEbGpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Assigning the Ratings into grouped categories\n",
        "ratings = {\n",
        "    'TV-PG': 'Older Kids',\n",
        "    'TV-MA': 'Adults',\n",
        "    'TV-Y7-FV': 'Older Kids',\n",
        "    'TV-Y7': 'Older Kids',\n",
        "    'TV-14': 'Teens',\n",
        "    'R': 'Adults',\n",
        "    'TV-Y': 'Kids',\n",
        "    'NR': 'Adults',\n",
        "    'PG-13': 'Teens',\n",
        "    'TV-G': 'Kids',\n",
        "    'PG': 'Older Kids',\n",
        "    'G': 'Kids',\n",
        "    'UR': 'Adults',\n",
        "    'NC-17': 'Adults'\n",
        "}\n",
        "data['target_ages'] = data['rating'].replace(ratings)"
      ],
      "metadata": {
        "id": "Co5A5KVwbGc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# type should be a catego\n",
        "data['type'] = pd.Categorical(data['type'])\n",
        "data['target_ages'] = pd.Categorical(data['target_ages'], categories=['Kids', 'Older Kids', 'Teens', 'Adults'])"
      ],
      "metadata": {
        "id": "aDf2EkjYcEmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "AQKMNANWcEjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating two extra columns\n",
        "tv_shows=data[data['type']=='TV Show']\n",
        "movies=data[data['type']=='Movie']"
      ],
      "metadata": {
        "id": "3qrKHDIQcEgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rating based on rating system of all TV Shows\n",
        "tv_ratings = tv_shows.groupby(['rating'])['show_id'].count().reset_index(name='count').sort_values(by='count',ascending=False)\n",
        "fig_dims = (14,7)\n",
        "fig, ax = plt.subplots(figsize=fig_dims)  \n",
        "sns.pointplot(x='rating',y='count',data=tv_ratings)\n",
        "plt.title('TV Show Ratings',size='20')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NF28o5BScEeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Movie Ratings based on Target Age Groups\n",
        "plt.figure(figsize=(14,6))\n",
        "plt.title('movie ratings')\n",
        "sns.countplot(x=movies['rating'],hue=movies['target_ages'],data=movies,order=movies['rating'].value_counts().index)"
      ],
      "metadata": {
        "id": "o6vG_qKVcEbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_year =movies['release_year'].value_counts().sort_index(ascending=False)"
      ],
      "metadata": {
        "id": "VXhn_fkpcEZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_year"
      ],
      "metadata": {
        "id": "4RdBif_GcEWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tvshows_year =tv_shows['release_year'].value_counts().sort_index(ascending=False)"
      ],
      "metadata": {
        "id": "MB_y4CdTcEUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing the movies and tv_shows based on the release year\n",
        "sns.set(font_scale=1.4)\n",
        "movies_year.plot(figsize=(12, 8), linewidth=2.5, color='maroon',label=\"Movies / year\",ms=3)\n",
        "tvshows_year.plot(figsize=(12, 8), linewidth=2.5, color='blue',label=\"TV Shows / year\")\n",
        "plt.xlabel(\"Years\", labelpad=15)\n",
        "plt.ylabel(\"Number\", labelpad=15)\n",
        "plt.title(\"Production growth yearly\", y=1.02, fontsize=22);\n",
        "     "
      ],
      "metadata": {
        "id": "GB0ONavncERH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Analysing how many movies released per year in last 20 years\n",
        "plt.figure(figsize=(15,5))\n",
        "sns.countplot(y=movies['release_year'],data=data,order=movies['release_year'].value_counts().index[0:20])"
      ],
      "metadata": {
        "id": "R8tWoLgMcEPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tvshows_year"
      ],
      "metadata": {
        "id": "QS4LMFlKcEJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Analysing how many movies released per year in last 15 years\n",
        "plt.figure(figsize=(15,5))\n",
        "sns.countplot(y=tv_shows['release_year'],data=data,order=tv_shows['release_year'].value_counts().index[0:20])"
      ],
      "metadata": {
        "id": "1QoDVC7Kc951"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "YOCmLOEJc923"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adding columns of month and year of addition\n",
        "\n",
        "data['month'] = pd.DatetimeIndex(data['date_added']).month\n",
        "data.head()"
      ],
      "metadata": {
        "id": "Jo1jeNH9c90b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the Countplot \n",
        "plt.figure(figsize=(12,10))\n",
        "ax=sns.countplot('month',data= data)\n",
        "     "
      ],
      "metadata": {
        "id": "yf1Wwr6Zc9yM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(15,6))\n",
        "\n",
        "sns.countplot(x='month', hue='type',lw=5, data=data, ax=ax)"
      ],
      "metadata": {
        "id": "Txmrqt55c9v_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Analysing top10 genre of the movies\n",
        "plt.figure(figsize=(14,6))\n",
        "plt.title('Top10 Genre of Movies',fontweight=\"bold\")\n",
        "sns.countplot(y=movies['listed_in'],data=movies,order=movies['listed_in'].value_counts().index[0:10])\n",
        "     "
      ],
      "metadata": {
        "id": "RYzssEEFc9t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Analysing top10 genres of TVSHOWS\n",
        "plt.figure(figsize=(14,6))\n",
        "plt.title('Top10 Genre of TV Shows',fontweight=\"bold\")\n",
        "sns.countplot(y=tv_shows['listed_in'],data=tv_shows,order=tv_shows['listed_in'].value_counts().index[0:10])"
      ],
      "metadata": {
        "id": "T8aMq8wrc9rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the distribution of Movie Durations\n",
        "plt.figure(figsize=(10,7))\n",
        "#Regular Expression pattern \\d is a regex pattern for digit + is a regex pattern for at leas\n",
        "sns.distplot(movies['duration'].str.extract('(\\d+)'),kde=False, color=['red'])\n",
        "plt.title('Distplot with Normal distribution for Movies',fontweight=\"bold\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SJQP9bbTc9pH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the distribution of TV SHOWS\n",
        "plt.figure(figsize=(30,6))\n",
        "plt.title(\"Distribution of TV Shows duration\",fontweight='bold')\n",
        "sns.countplot(x=tv_shows['duration'],data=tv_shows,order = tv_shows['duration'].value_counts().index)"
      ],
      "metadata": {
        "id": "79QdJ4quc9lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies['minute'] = movies['duration'].str.extract('(\\d+)').apply(pd.to_numeric)\n",
        "duration_year = movies.groupby(['rating'])['minute'].mean()\n",
        "duration_df=pd.DataFrame(duration_year).sort_values('minute')\n",
        "plt.figure(figsize=(12,6))\n",
        "ax=sns.barplot(x=duration_df.index, y=duration_df.minute)"
      ],
      "metadata": {
        "id": "D_nz6IXKc9j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Analysing top15 countries with most content \n",
        "plt.figure(figsize=(18,5))\n",
        "sns.countplot(x=data['country'],order=data['country'].value_counts().index[0:15],hue=data['type'])\n",
        "plt.xticks(rotation=50)\n",
        "plt.title('Top 15 countries with most contents', fontsize=15, fontweight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LUEo_7e0c9ZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#top_two countries where netflix is most popular\n",
        "country=data['country'].value_counts().reset_index()\n",
        "country"
      ],
      "metadata": {
        "id": "IWogI71cdZcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the Horizontal bar plot for top 10 country contains Movie & TV Show split\n",
        "country_order = data['country'].value_counts()[:11].index\n",
        "content_data = data[['type', 'country']].groupby('country')['type'].value_counts().unstack().loc[country_order]\n",
        "content_data['sum'] = content_data.sum(axis=1)\n",
        "content_data_ratio = (content_data.T / content_data['sum']).T[['Movie', 'TV Show']].sort_values(by='Movie',ascending=False)[::-1]\n",
        "\n",
        "# Plotting the barh\n",
        "fig, ax = plt.subplots(1,1,figsize=(15, 8),)\n",
        "\n",
        "ax.barh(content_data_ratio.index, content_data_ratio['Movie'], \n",
        "        color='crimson', alpha=0.8, label='Movie')\n",
        "ax.barh(content_data_ratio.index, content_data_ratio['TV Show'], left=content_data_ratio['Movie'], \n",
        "        color='black', alpha=0.8, label='TV Show')"
      ],
      "metadata": {
        "id": "81ogaDPfdZZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing data for heatmap\n",
        "data['count'] = 1\n",
        "data1 = data.groupby('country')[['country','count']].sum().sort_values(by='count',ascending=False).reset_index()[:10]\n",
        "data1 = data1['country']\n",
        "\n",
        "\n",
        "df_heatmap = data.loc[data['country'].isin(data1)]\n",
        "df_heatmap = pd.crosstab(df_heatmap['country'],df_heatmap['target_ages'],normalize = \"index\").T\n",
        "df_heatmap"
      ],
      "metadata": {
        "id": "BKIvVxnLpteJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the heatmap\n",
        "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
        "\n",
        "country_order2 = ['United States', 'India', 'United Kingdom', 'Canada', 'Japan', 'France', 'South Korea', 'Spain',\n",
        "       'Mexico']\n",
        "\n",
        "age_order = ['Adults', 'Teens', 'Older Kids', 'Kids']\n",
        "\n",
        "sns.heatmap(df_heatmap.loc[age_order,country_order2],cmap=\"YlGnBu\",square=True, linewidth=2.5,cbar=False,\n",
        "            annot=True,fmt='1.0%',vmax=.6,vmin=0.05,ax=ax,annot_kws={\"fontsize\":12})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FDNyf_fgqCQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['date_added'] = pd.to_datetime(data['date_added'])\n",
        "movies['year_added'] = data['date_added'].dt.year\n",
        "data"
      ],
      "metadata": {
        "id": "mOZ4ylpidZRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies['originals'] = np.where(movies['release_year'] == movies['year_added'], 'Yes', 'No')\n",
        "# pie plot showing percentage of originals and others in movies\n",
        "fig, ax = plt.subplots(figsize=(5,5),facecolor=\"#363336\")\n",
        "ax.patch.set_facecolor('#363336')\n",
        "explode = (0, 0.1)\n",
        "ax.pie(movies['originals'].value_counts(), explode=explode, autopct='%.2f%%', labels= ['Others', 'Originals'],\n",
        "       shadow=True, startangle=90,textprops={'color':\"black\", 'fontsize': 20}, colors =['red','#F5E9F5'])"
      ],
      "metadata": {
        "id": "ezev0TqCdn2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hypothesis"
      ],
      "metadata": {
        "id": "JlxC5LcKdsvc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. hypothesis testing\n",
        "\n",
        "HO:movies rated for kids and older kids are at least two hours long.\n",
        "\n",
        "H1:movies rated for kids and older kids are not at least two hours long."
      ],
      "metadata": {
        "id": "jezuXsB9d1bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies"
      ],
      "metadata": {
        "id": "-O5TMSQgdvq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making copy of df_clean_frame\n",
        "df_hypothesis=data.copy()\n",
        "#head of df_hypothesis\n",
        "df_hypothesis.head()"
      ],
      "metadata": {
        "id": "IaPHCPqudvnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filtering movie from Type_of_show column\n",
        "df_hypothesis = df_hypothesis[df_hypothesis[\"type\"] == \"Movie\"]"
      ],
      "metadata": {
        "id": "w6WiRoOydvlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#with respect to each ratings assigning it into group of categories                 \n",
        "ratings_ages = {\n",
        "    'TV-PG': 'Older Kids',\n",
        "    'TV-MA': 'Adults',\n",
        "    'TV-Y7-FV': 'Older Kids',\n",
        "    'TV-Y7': 'Older Kids',\n",
        "    'TV-14': 'Teens',\n",
        "    'R': 'Adults',\n",
        "    'TV-Y': 'Kids',\n",
        "    'NR': 'Adults',\n",
        "    'PG-13': 'Teens',\n",
        "    'TV-G': 'Kids',\n",
        "    'PG': 'Older Kids',\n",
        "    'G': 'Kids',\n",
        "    'UR': 'Adults',\n",
        "    'NC-17': 'Adults'\n",
        "}\n",
        "\n",
        "df_hypothesis['target_ages'] = df_hypothesis['rating'].replace(ratings_ages)\n",
        "#let's see unique target ages \n",
        "df_hypothesis['target_ages'].unique()"
      ],
      "metadata": {
        "id": "88W6k0l_dvc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Another category is target_ages (4 classes).\n",
        "df_hypothesis['target_ages'] = pd.Categorical(df_hypothesis['target_ages'], categories=['Kids', 'Older Kids', 'Teens', 'Adults'])\n",
        "#from duration feature extractin string part and after extracting Changing the object type to numeric\n",
        "df_hypothesis['duration']= df_hypothesis['duration'].str.extract('(\\d+)')\n",
        "df_hypothesis['duration'] = pd.to_numeric(df_hypothesis['duration'])\n",
        "#head of df_\n",
        "df_hypothesis.head(3)"
      ],
      "metadata": {
        "id": "hq3xpWzOeFda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#group_by duration and target_ages                 \n",
        "group_by_= df_hypothesis[['duration','target_ages']].groupby(by='target_ages')\n",
        "#mean of group_by variable\n",
        "group=group_by_.mean().reset_index()\n",
        "group"
      ],
      "metadata": {
        "id": "APCxhNVneFaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#In A and B variable grouping values \n",
        "A= group_by_.get_group('Kids')\n",
        "B= group_by_.get_group('Older Kids')\n",
        "#mean and std. calutation for kids and older kids variables\n",
        "M1 = A.mean()\n",
        "S1 = A.std()\n",
        "\n",
        "M2= B.mean()\n",
        "S2 = B.std()\n",
        "\n",
        "print('Mean for movies rated for Kids {} \\n Mean for  movies rated for older kids {}'.format(M1,M2))\n",
        "print('Std for  movies rated for Older Kids {} \\n Std for  movies rated for kids {}'.format(S2,S1))"
      ],
      "metadata": {
        "id": "O5n3zq66eFYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import stats \n",
        "from scipy import stats\n",
        "#length of groups and DOF\n",
        "n1 = len(A)\n",
        "n2= len(B)\n",
        "print(n1,n2)\n",
        "\n",
        "dof = n1+n2-2\n",
        "print('dof',dof)\n",
        "\n",
        "sp_2 = ((n2-1)*S1**2  + (n1-1)*S2**2) / dof\n",
        "print('SP_2 =',sp_2)\n",
        "\n",
        "sp = np.sqrt(sp_2)\n",
        "print('SP',sp)\n",
        "\n",
        "#tvalue\n",
        "t_val = (M1-M2)/(sp * np.sqrt(1/n1 + 1/n2))\n",
        "print('tvalue',t_val[0])"
      ],
      "metadata": {
        "id": "L_wyxRLLeFVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#t-distribution\n",
        "stats.t.ppf(0.025,dof)"
      ],
      "metadata": {
        "id": "CnaVkuDaeFTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#t-distribution\n",
        "stats.t.ppf(0.975,dof)\n",
        "     "
      ],
      "metadata": {
        "id": "1iLQYxvReUuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. HYPOTHESIS TESTING\n",
        "\n",
        "H1:The duration which is more than 90 mins are movies\n",
        "\n",
        "HO:The duration which is more than 90 mins are NOT movies"
      ],
      "metadata": {
        "id": "QWk9CKYieWQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#making copy of df_clean_frame\n",
        "df_hypothesis=data.copy()\n",
        "#head of df_hypothesis\n",
        "df_hypothesis.head()"
      ],
      "metadata": {
        "id": "anb5JHeledsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_hypothesis['duration']= df_hypothesis['duration'].str.extract('(\\d+)')\n",
        "df_hypothesis['duration'] = pd.to_numeric(df_hypothesis['duration'])\n",
        "#head of df_\n"
      ],
      "metadata": {
        "id": "c_jE03yAep3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_hypothesis['type'] = pd.Categorical(df_hypothesis['type'], categories=['Movie','TV Show'])\n",
        "#from duration feature extractin string part and after extracting Changing the object type to numeric\n",
        "#df_hypothesis['duration']= df_hypothesis['duration'].str.extract('(\\d+)')\n",
        "#df_hypothesis['duration'] = pd.to_numeric(df_hypothesis['duration'])\n",
        "#head of df_\n",
        "df_hypothesis.head(3)\n"
      ],
      "metadata": {
        "id": "8qr451lCepzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#group_by duration and TYPE                 \n",
        "group_by_= df_hypothesis[['duration','type']].groupby(by='type')\n",
        "#mean of group_by variable\n",
        "group=group_by_.mean().reset_index()\n",
        "group\n",
        "     "
      ],
      "metadata": {
        "id": "90D-y9wYepxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#In A and B variable grouping values \n",
        "A= group_by_.get_group('Movie')\n",
        "B= group_by_.get_group('TV Show')\n",
        "#mean and std\n",
        "M1 = A.mean()\n",
        "S1 = A.std()\n",
        "\n",
        "M2= B.mean()\n",
        "S2 = B.std()\n",
        "\n",
        "print('Mean  {}'.format(M1,M2))\n",
        "print('Std  {}'.format(S2,S1))\n",
        "     "
      ],
      "metadata": {
        "id": "_BfekBJQepvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import stats \n",
        "from scipy import stats\n",
        "#length of groups and DOF\n",
        "n1 = len(A)\n",
        "n2= len(B)\n",
        "print(n1,n2)\n",
        "\n",
        "dof = n1+n2-2\n",
        "print('dof',dof)\n",
        "\n",
        "sp_2 = ((n2-1)*S1**2  + (n1-1)*S2**2) / dof\n",
        "print('SP_2 =',sp_2)\n",
        "\n",
        "sp = np.sqrt(sp_2)\n",
        "print('SP',sp)\n",
        "\n",
        "#tvalue\n",
        "t_val = (M1-M2)/(sp * np.sqrt(1/n1 + 1/n2))\n",
        "print('tvalue',t_val[0])"
      ],
      "metadata": {
        "id": "WbVdAjKbeptK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#t-distribution\n",
        "stats.t.ppf(0.025,dof)"
      ],
      "metadata": {
        "id": "6AEEN43re4hJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#t-distribution\n",
        "stats.t.ppf(0.975,dof)"
      ],
      "metadata": {
        "id": "QO8kpV5Xe4Vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature engineering"
      ],
      "metadata": {
        "id": "QaR9Ly26e-H9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "metadata": {
        "id": "E5Cjdd6ce--p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "oeHfX7DHe_vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "metadata": {
        "id": "qW6id-rde_sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['description'].astype(str)"
      ],
      "metadata": {
        "id": "sawnPCFbe_pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# after above all the changes, those features are in list format, so making list of description feature\n",
        "data['description'] = data['description'].apply(lambda x: x.split(' '))"
      ],
      "metadata": {
        "id": "jgIt_h6ne_ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting text feature to string from list\n",
        "data['description']= data['description'].apply(lambda x: \" \".join(x))\n",
        "# making all the words in text feature to lowercase\n",
        "data['description']= data['description'].apply(lambda x: x.lower())"
      ],
      "metadata": {
        "id": "cqHovICse_k1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuation(text):\n",
        "    '''a function for removing punctuation'''\n",
        "    import string\n",
        "    # replacing the punctuations with no space, \n",
        "    # which in effect deletes the punctuation marks \n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    # return the text stripped of punctuation marks\n",
        "    return text.translate(translator)\n",
        "# applying above function on text feature\n",
        "data['description']= data['description'].apply(remove_punctuation)"
      ],
      "metadata": {
        "id": "FBZJLvT3e_ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['description'][0:10]"
      ],
      "metadata": {
        "id": "SpiZctLCfReg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using nltk library to download stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "sw=stopwords.words('english')\n",
        "#Defining stopwords \n",
        "def stopwords(text):\n",
        "    '''a function for removing the stopword'''\n",
        "    text = [word for word in text.split() if word not in sw]\n",
        "    # joining the list of words with space separator\n",
        "    return \" \".join(text)\n",
        "# applying above function on text feature\n",
        "data['description']=data['description'].apply(stopwords)\n",
        "# this is how value in text looks like after removing stopwords\n",
        "data['description'][0]"
      ],
      "metadata": {
        "id": "zfbDvjxefRa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing TfidVectorizer from sklearn library\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "vl5tFSJ2fRY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying Tfidf Vectorizer\n",
        "tfidfmodel = TfidfVectorizer(max_features=5000)\n",
        "X_tfidf = tfidfmodel.fit_transform(data['description'])\n",
        "X_tfidf.shape"
      ],
      "metadata": {
        "id": "2PmylxeSfaS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert X into array form for clustering\n",
        "X = X_tfidf.toarray() "
      ],
      "metadata": {
        "id": "BCpmR7_5faP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "clustering algorithms"
      ],
      "metadata": {
        "id": "V7HlSoBnfd_b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Kmean\n",
        "\n",
        "Finding the optimal number of clusters using the elbow method"
      ],
      "metadata": {
        "id": "yIvbWf20fhSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#finding optimal number of clusters using the elbow method  \n",
        "from sklearn.cluster import KMeans  \n",
        "wcss_list= []  #Initializing the list for the values of WCSS  \n",
        "  \n",
        "#Using for loop for iterations from 1 to 30.  \n",
        "for i in range(1, 30):  \n",
        "    kmeans = KMeans(n_clusters=i, init='k-means++', random_state= 42)  \n",
        "    kmeans.fit(X)  \n",
        "    wcss_list.append(kmeans.inertia_)  \n",
        "plt.plot(range(1, 30), wcss_list)  \n",
        "plt.title('The Elobw Method Graph')  \n",
        "plt.xlabel('Number of clusters(k)')  \n",
        "plt.ylabel('wcss_list')  \n",
        "plt.show()  "
      ],
      "metadata": {
        "id": "m5m8BmPOfjtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "#sillhoute score of clusters \n",
        "sill = [] \n",
        "for i in range(2,30):\n",
        "    model = KMeans(n_clusters=i,init ='k-means++',random_state=51)\n",
        "    model.fit(X)\n",
        "    y1 = model.predict(X)\n",
        "    score = silhouette_score(X,y1)\n",
        "    sill.append(score)\n",
        "    print('cluster: %d \\t Sillhoute: %0.4f'%(i,score))"
      ],
      "metadata": {
        "id": "MU2-7Iy6fkuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting Sillhoute's score\n",
        "plt.plot(sill,'bs--')\n",
        "plt.xticks(list(range(0,30)),list(range(2,30)))\n",
        "plt.grid(),plt.xlabel('Number of cluster')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yFceB2D3fkq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training the K-means model on a dataset  \n",
        "kmeans = KMeans(n_clusters= 26, init='k-means++', random_state= 42)  \n",
        "y_predict= kmeans.fit_predict(X) \n",
        "     "
      ],
      "metadata": {
        "id": "75S6mIaefko9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation"
      ],
      "metadata": {
        "id": "b1Q6SBHsfyt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict the clusters and evaluate the silhouette score\n",
        "\n",
        "score = silhouette_score(X, y_predict)\n",
        "print(\"Silhouette score is {}\".format(score))\n"
      ],
      "metadata": {
        "id": "8R6NRxegfkmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#davies_bouldin_score of our clusters \n",
        "from sklearn.metrics import davies_bouldin_score\n",
        "davies_bouldin_score(X, y_predict)"
      ],
      "metadata": {
        "id": "pjh1j2tEfkkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding a seperate column for the cluster\n",
        "data[\"cluster\"] = y_predict"
      ],
      "metadata": {
        "id": "xL9NsNYef4cF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['cluster'].value_counts()\n",
        "     "
      ],
      "metadata": {
        "id": "hYdY4MjOf4ZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(15,6))\n",
        "sns.countplot(x='cluster', hue='type',lw=5, data=data, ax=ax)"
      ],
      "metadata": {
        "id": "DRxw2JwFgAkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SCATTER PLOT FOR CLUSTERS\n",
        "fig = px.scatter(data, y=\"description\", x=\"cluster\",color=\"cluster\")\n",
        "fig.update_traces(marker_size=100)\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "LNhdLMN6gAhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dendogram"
      ],
      "metadata": {
        "id": "e3KNwwKGgIlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.cluster.hierarchy as shc\n",
        "plt.figure(figsize =(8, 8))\n",
        "plt.title('Visualising the data')\n",
        "Dendrogram = shc.dendrogram((shc.linkage(X, method ='ward')))"
      ],
      "metadata": {
        "id": "DTeI-Y4AgKEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.AgglomerativeClustering"
      ],
      "metadata": {
        "id": "Wdsl_djIgLo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting our variable in Agglomerative Clusters\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "aggh = AgglomerativeClustering(n_clusters=6, affinity='euclidean', linkage='ward')  \n",
        "aggh.fit(X)\n",
        "#Predicting using our model\n",
        "y_hc=aggh.fit_predict(X)"
      ],
      "metadata": {
        "id": "vqAFXDu0gRHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_hierarchical =data.copy()\n",
        "#creating a column where each row is assigned to their separate cluster\n",
        "df_hierarchical['cluster'] = aggh.labels_\n",
        "df_hierarchical.head()"
      ],
      "metadata": {
        "id": "wmetaOhmgRqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "evaluation"
      ],
      "metadata": {
        "id": "tkRaqgjgga-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Silhouette Coefficient\n",
        "print(\"Silhouette Coefficient: %0.3f\"%silhouette_score(X,y_hc, metric='euclidean'))"
      ],
      "metadata": {
        "id": "PZ0dFeZygcJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#davies_bouldin_score of our clusters \n",
        "from sklearn.metrics import davies_bouldin_score\n",
        "davies_bouldin_score(X, y_hc)"
      ],
      "metadata": {
        "id": "otBR-AxngcvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "from elbow and sillhoute score ,optimal of 26 clusters formed , K Means is best for identification than Hierarchical as the evaluation metrics also indicates the same.in kmean cluster 0 has the highest number of datapoints\n",
        "and evnly distributed for other cluster\n",
        "\n",
        "Netflix has 5372 movies and 2398 TV shows,\n",
        "there are more number movies on Netflix than TV shows.\n",
        "\n",
        "TV-MA has the highest number of ratings for tv shows i,e adult ratings\n",
        "\n",
        "highest number of movies released in 2017 and 2018\n",
        "\n",
        "highest number of movies released in 2020 The number of movies on Netflix is growing significantly faster than the number of TV shows. We saw a huge increase in the number of movies and television episodes after 2015. there is a significant drop in the number of movies and television episodes produced after 2020. It appears that Netflix has focused more attention on increasing Movie content than TV Shows. Movies have increased much more dramatically than TV shows\n",
        "\n",
        "the most content is added to Netflix from october to january\n",
        "\n",
        "Documentaries are the top most genre in netflix which is fllowed by standup comedy and Drams and international movies\n",
        "\n",
        "kids tv is the top most TV show genre in netflix\n",
        "\n",
        "most of the movies have duration of between 50 to 150\n",
        "\n",
        "highest number of tv_shows consistig of single season\n",
        "\n",
        "Those movies that have a rating of NC-17 have the longest average duration.\n",
        "\n",
        "When it comes to movies having a TV-Y rating, they have the shortest runtime on average\n",
        "\n",
        "unitated states has the highest number of content on the netflix ,followed by india\n",
        "\n",
        "india has highest number of movies in netflix\n",
        "\n",
        "30% movies released on Netflix.\n",
        "\n",
        "70% movies added on Netflix were released earlier by different mode."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your EDA Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}